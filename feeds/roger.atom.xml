<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Roger</title><link href="http://rogerarm.github.io/" rel="alternate"></link><link href="http://rogerarm.github.io/feeds/roger.atom.xml" rel="self"></link><id>http://rogerarm.github.io/</id><updated>2015-12-31T00:00:00+01:00</updated><entry><title>2015年历程与感悟</title><link href="http://rogerarm.github.io/2015nian-li-cheng-yu-gan-wu.html" rel="alternate"></link><updated>2015-12-31T00:00:00+01:00</updated><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-12-31:2015nian-li-cheng-yu-gan-wu.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;一年很快又结束了，以前一直没有写总结的习惯，一年过去了，感觉也没有留下什么。于是今年特此写篇总结，记录下这一年的点点滴滴，再思考下明年的期望。&lt;/p&gt;
&lt;h1&gt;生活&lt;/h1&gt;
&lt;p&gt;今年的生活比较简单，简单到回想一年，只能想起工作和回家两件事。在帝都工作的人也许都这样，生活节奏太快。今年锻炼也比较少，去年有时还和地总去奥体游泳，今年自从地总找了个女友后，找我除了帮他办事以外，绝对没有第二件事，对他是彻底无语。一直想去奥森公园锻炼的，也没有去过，希望明年可以加强下锻炼。&lt;/p&gt;
&lt;p&gt;周围结婚的同学越来越多了，打开朋友圈，不是婚纱照就是密月照。很多同学的婚礼也没来的及参加，感到非常的遗憾。&lt;/p&gt;
&lt;h1&gt;工作&lt;/h1&gt;
&lt;p&gt;首先非常荣幸，又在我司平安的渡过了第二个元旦。以前一直不信，工作再累也不会过劳死，来到我司后，发现一切皆有可能。&lt;/p&gt;
&lt;p&gt;相比于去年，今年的工作更加忙了。仔细回想，技术上没有太大长进，对我司的推拉扯（推动，拉通，扯皮）文化倒是理解的刻骨铭心。以前开个会说话还吞吞吐吐，现在就算屁事没有，拉一个会也能扯上半小时。&lt;/p&gt;
&lt;p&gt;今年对技术方面的书看的不多，主要还是查找资料，和大家交流。如果说去年一年是对分布式数据库产品有个入门的了解，那么今年可以说对大数据生态有了个入门的概念。好比别人说什么hadoop, hbase, hive, spark,pig等这些名词的时候能扯上一二。&lt;/p&gt;
&lt;p&gt;交流和沟通能力上还是有了一点提高，以前做一件事总是一个人闷头搞，知道的太少，也不知道别人在做啥，问了别人给你讲也听不懂。现在基本上谁在做啥都能扯两句。英语交流能力有了一点突破，以前和印度人沟通都是共享个屏幕，然后两个人开始打字，感觉特别囧，后来这种方式效率实在太低，完全不符合我司快节奏的氛围，于是只能硬着头皮说几句简单的口语，虽然很烂，但还好大家能互相听懂一二。以后还是要多多练习，慢慢提高，毕竟口语是基本能力。&lt;/p&gt;
&lt;p&gt;明年在技术上希望能对数据库有个更加深层次的理解，很多机制还需要学习，真心希望有这个时间。&lt;/p&gt;
&lt;h1&gt;博客&lt;/h1&gt;
&lt;p&gt;今年年中的时候终于捡起了github博客，两年没有维护了，年中时写了几篇博客，但还是太少，下半年实在太忙，完全没有这个精力，希望明年能写更多，养成一个善于总结与记录的好习惯。还有就是这个博客主题太丑了，毕竟过了两年，一直想换也没空。&lt;/p&gt;
&lt;h1&gt;兴趣&lt;/h1&gt;
&lt;p&gt;今年也没培养起什么好的兴趣，除了没事听听音乐就是看看电视，一直想看看非技术类书的愿望也没有实现，希望明年能有个好的开始。&lt;/p&gt;
&lt;h1&gt;旅游&lt;/h1&gt;
&lt;p&gt;今年也没怎么出去过旅游，本打算和家人一起去韩国的，结果也因为签证太晚而被抛弃，仅限于在帝都周边的地区逛逛。希望明年可以安排一次有意思的旅游。&lt;/p&gt;
&lt;h1&gt;展望&lt;/h1&gt;
&lt;p&gt;总结今年就这么平平淡淡的过去了，工作的第二年，很快将进入第三年了，希望新的一年里更加美好。&lt;/p&gt;</summary></entry><entry><title>数据库中的High availability</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-high-availability.html" rel="alternate"></link><updated>2015-08-24T00:00:00+02:00</updated><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-08-24:shu-ju-ku-zhong-de-high-availability.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在传统关系型数据库中有一个非常重要的特性就是high availability，简称高可用。简而言之就是如果一台服务器坏了，仍然系统要保证可用性，通常的实现方式有以下几种，&lt;/p&gt;
&lt;blockquote&gt;
&lt;h5&gt;1： 使用一主一备或多备的方式来同步数据；&lt;/h5&gt;
&lt;h5&gt;2： 使用共享磁阵的方式共享数据；&lt;/h5&gt;
&lt;h5&gt;3： 使用分布式文件系统来保证数据的安全；&lt;/h5&gt;
&lt;/blockquote&gt;
&lt;p&gt;本篇博客只探讨单机数据库中的高可用，对于分布式数据库中的高可用可以到下次再探讨。&lt;/p&gt;
&lt;p&gt;通常单机数据库采用方法1来实现high availability，一台服务器作为主机，另一台作为热备。主机实时将事务日志xlog同步给备机，备机将日志写盘后回复主机写入的位置（例如LSN，一个uint64位顺序递增数值，并假设它永远用不完），主机将事务等待队列中小于该LSN的事务全部提交。&lt;/p&gt;
&lt;p&gt;主备复制流程如图1所示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Note&lt;/span&gt; &lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Primary&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="n"&gt;transaction&lt;/span&gt;
&lt;span class="n"&gt;Note&lt;/span&gt; &lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Primary&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;flush&lt;/span&gt; &lt;span class="n"&gt;xlog&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;disk&lt;/span&gt;
&lt;span class="n"&gt;Primary&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Standby&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;send&lt;/span&gt; &lt;span class="n"&gt;xlog&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Standby&lt;/span&gt;
&lt;span class="n"&gt;Note&lt;/span&gt; &lt;span class="n"&gt;right&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Standby&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;flush&lt;/span&gt; &lt;span class="n"&gt;xlog&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;disk&lt;/span&gt;
&lt;span class="n"&gt;Standby&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Primary&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;reply&lt;/span&gt; &lt;span class="n"&gt;xlog&lt;/span&gt; &lt;span class="n"&gt;location&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Primary&lt;/span&gt;
&lt;span class="n"&gt;Note&lt;/span&gt; &lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Primary&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;commit&lt;/span&gt; &lt;span class="n"&gt;transaction&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用主备方案时，通常会有一套第三方的集群管理软件来监测主备机的状态，当主机宕机时，第三方集群管理软件可以将备机升主，使业务做到不间断。
这样看是完美，然而如果第三方集群管理软件一旦与主机网络断连，误以为主机宕机，让备机升主，此时出现双主，然而由图1可知，主机开始一个事务是先刷写xlog，再发送给备机，当出现双主时，两个主机均会写下日志，此时这一对主备的xlog便出现不一致，即使重启一个主机将其设为备机也无法与新主机同步，因为已经有不一样的xlog日志了。
在PostgreSQL与MySQL数据库中经常会遇到这类问题。当主备设置为同步模式时，可以避免数据一致性的问题，因为没有备机写事务无法提交。&lt;/p&gt;
&lt;p&gt;解决这个问题的方法有两个：&lt;/p&gt;
&lt;blockquote&gt;
&lt;h5&gt;1： 修改主机写xlog的顺序，当主机将一个事务产生的xlog发送到备机后，自己再flush磁盘，这样便可以避免双主后的主备xlog不一致。&lt;/h5&gt;
&lt;h5&gt;2： 将备机进行重建，重建分为两种，一种是全量重建，如果主机数据量很大时，全量重建将非常耗时，这并不符合高可用的理念；另一种是增量重建，就是将双主中不一样的xlog开始分析，以一个主机为准，将另一个主机中不一样的xlog进行undo。以PostgreSQL为例，它并没有日志undo机制，因此这个问题在PostgreSQL中一直是个难题。然而最近发布的PG9.5版本中增加了一个工具pg_rewind，可以使用增量build的方式来解决双主的问题。&lt;/h5&gt;
&lt;/blockquote&gt;</summary></entry><entry><title>数据库中的full page write</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-full-page-write.html" rel="alternate"></link><updated>2015-08-09T00:00:00+02:00</updated><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-08-09:shu-ju-ku-zhong-de-full-page-write.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在传统关系型数据库中有一个功能称为full page write，这个功能是为了避免机械磁盘在写的时候无法保证原子性而设计的，也可以认为是一个古老的功能，但是其思想值得借鉴。以下以PostgreSQL数据库的实现为例子解释这一设计思想。&lt;/p&gt;
&lt;p&gt;假设每次写事务日志时都有一个唯一的标记称为LSN，它顺序增长，假设用不完。我们在写每条日志时头部都有LSN标记。&lt;/p&gt;
&lt;p&gt;当数据库系统运行时，如果此时系统正在刷写页面（假设page大小为8KB）时系统断电，当该服务器使用的磁盘不带电池时，磁盘刷写数据只能保证512B字节的原子性（因为磁盘的一个扇区是512B） 。 因此此时可能造成一个页面中只有页头的512B刷写到磁盘上，而剩下的数据未更新，此时如果系统启动重新恢复过程中，首先会判断该LSN是否比恢复日志中的LSN大，如果大表示页面数据为未来的，即跳过恢复。然而此时页面数据因为不具有原子性并不是最新，导致数据出现不一致。&lt;/p&gt;
&lt;p&gt;解决这个问题的一个方法就是在每次checkpoint之后，如果读取的一个页面是第一次读取，更改该页面时，也就是写更新该页面xlog日志时把整个页面写入xlog中，如果在后面宕机再恢复时无条件将该页面替换磁盘上的页面，因为此时磁盘上的页面可能无法保证页面的原子性。而后面的日志恢复过程中，可能刷坏的页面已经被替换掉，LSN的判断也不可能出现错误，因此可以有效的解决该问题。&lt;/p&gt;
&lt;p&gt;该方法的一个缺陷就是可能会造成xlog日志文件很大，在主备同步过程中，网络传输的日志过多，造成性能下降。&lt;/p&gt;
&lt;p&gt;然而在现代数据库系统中使用的磁盘通常可能带电池，而可以保证写page的原子性，因此该功能通常可以关闭。并且未来可能会使用更高端的存储介质，比如SSD或NVRAM，性能将是机械磁盘的几个数量级。但是该问题的解决方案还是值得借鉴的，在我们无法保证磁盘上页面数据最新并且完整时，可以使用该full page write思想，出现这个情况的场景比如时，并行恢复，数据页复制等等情况下。&lt;/p&gt;</summary></entry><entry><title>数据库中的checkpoint</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-checkpoint.html" rel="alternate"></link><updated>2015-08-02T00:00:00+02:00</updated><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-08-02:shu-ju-ku-zhong-de-checkpoint.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在上一篇博客中我们讲到目前大众型的关系型数据库都采用了WAL思想，就是将page的更新只在内存中操作，并记录相应的事务日志，提交事务时保证事务日志先提交。&lt;/p&gt;
&lt;p&gt;然而我们可以考虑这里面的一个问题，就是装载page的内存容量到底要设多大才合适，工程中服务器的内存是有限的，假设设置为4GB大小，那么这4GB用完了怎么办呢？还有就是我们记录的事务日志（假设称其为xlog）多久才删除呢？&lt;/p&gt;
&lt;p&gt;这便涉及到另一个通常使用的思想叫checkpoint，目前大部分的关系型数据库都会使用这一技术。简而言之就是当到一定时候我们就把内存中的数据全部刷盘，然后删除这个时间点之前的所有xlog，因为这个时间点所有的内存数据都刷到磁盘了，之前的这些xlog已经不需要恢复了，下次系统如果出现异常，数据库系统便可以从最近一次checkpoint点来启动恢复，重新redo回内存中的这些操作。&lt;/p&gt;
&lt;p&gt;使用这个方法便便可以保证数据库系统可以循环并正常的运行了，通常checkpoint启动可以受xlog个数，时间，业务线程的请求等等控制。并且系统在做checkpoint时会将大量的page fsync到磁盘，因此此时的IO量很大，通常此时性能不好，使用TPCC测试时可以看到tpmc的曲线在这个点出现明显的下降。&lt;/p&gt;
&lt;p&gt;解决这个问题的一个方法就是系统中可以再运行一个后台线程，慢慢的整理内存中的page数据，将没有弄脏的page扔掉，慢慢的刷写一些page，可以腾出一些内存空间，以防数据库的内存空间因为满了而导致系统性能下降，也可以降低checkpoint启动时造成的系统性能下降的时间窗。&lt;/p&gt;</summary></entry><entry><title>数据库中的WAL</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-wal.html" rel="alternate"></link><updated>2015-07-26T00:00:00+02:00</updated><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-07-26:shu-ju-ku-zhong-de-wal.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在数据库系统中，通常大家会讨论到WAL，其称为write-ahead log，预写式日志。是目前传统关系型数据库中提升事务提交性能的一种常用方法。&lt;/p&gt;
&lt;p&gt;在描述WAL之前，我们先讨论下数据库存储的实现方式。&lt;/p&gt;
&lt;p&gt;在计算机系统刚刚萌芽期间，人们希望可以将一些结构化数据（比如一张表数据）存储起来，并且具有永久性。通常的做法就是将这些数据一行一行的写入一个文件，当想使用时便打开一行一行读取，当然写入和打开都是通过程序让计算机去操作。当数据操作不是很频繁时，这样不失为一种好方法。&lt;/p&gt;
&lt;p&gt;然而如果数据在频繁的做操作，每次读取磁盘和写入磁盘都是非常耗时的。那么人们便想，CPU操作内存的速度是操作磁盘速度的几十甚至几百倍，能不能将数据按页面划分，将这些页面读取到内存中，每次数据库系统在更新时都直接更新内存中的数据页面，而不用每次去读写磁盘。&lt;/p&gt;
&lt;p&gt;然而当系统一直运行正常的时候，性能固然是很好，但是一旦系统出现异常宕机时，内存中的数据便永久丢失，这在数据库系统中是绝对不允许的。解决这个问题的方法就是每次在提交事务之前记录事务日志，并且将事务日志刷到磁盘上后再提交事务。这样便保证了即使系统宕机，再次启动的时候数据库也可以从事务日志中恢复内存中的数据，这便是WAL，这些日志通常也被称为redo日志。&lt;/p&gt;
&lt;p&gt;可能大家会有个疑问，同样都是要fsync到磁盘，写wal与写page有什么区别呢？这便涉及机械磁盘中一个随机IO与顺序IO的问题。写wal时是所有事务日志都写到一个文件中，最后fsync到磁盘就可以。而写page时会涉及到不同表和不同page的文件，因此需要随机的写磁盘上不同位置，这样在机械磁盘的实现上是相对较慢的。&lt;/p&gt;
&lt;p&gt;使用写事务日志来代替频繁的读写磁盘，可以提升数据库的并发性能，因此wal也是关系型数据库乃至其它新型分布式系统中一种常用的技术。&lt;/p&gt;</summary></entry><entry><title>事务隔离级别</title><link href="http://rogerarm.github.io/shi-wu-ge-chi-ji-bie.html" rel="alternate"></link><updated>2015-07-19T00:00:00+02:00</updated><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-07-19:shi-wu-ge-chi-ji-bie.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在数据库系统中，如果每个并发操作都是原子的，就好比如果都是
&lt;code&gt;set a = 3;&lt;/code&gt;
这类的简单操作，那么数据库系统中不需要锁或隔离级别来控制并发，因为它本身就是原子的。&lt;/p&gt;
&lt;p&gt;但是数据库中有一个重要的个功能叫事务，就是可以将多个操作定义为一个事务块，这个事务块要么都成功，要么都失败。这样就加大了数据库在并发时的复杂性。&lt;/p&gt;
&lt;p&gt;解决这个问题的一种方法就是每个单元都加互斥锁，让每个事务串行的进行下去，这就是串行化隔离级别。&lt;/p&gt;
&lt;p&gt;这种方法明显性能不好，无法保证数据库系统的大并发功能。我们可以思考如果把互斥锁改为读写锁，这样在读上可以并发，这是一个性能的提升。使用读写锁时，有两种情况：第一种是读读并发，读读并发可能会造成幻读的情况，这就是可重复读隔离级别。第二种是不仅可以读读并发，还可以读写并发，就是读锁可被升级为写锁，读写并发时不满足可重复读，这就是读已提交隔离级别。&lt;/p&gt;
&lt;p&gt;然后还有一种方法就是只在写时加锁，这样可以实现读读并发，读写并发，写读并发，写读并发过程中会造成脏读，这类隔离级别通常称为读未提交。&lt;/p&gt;
&lt;p&gt;在SQL92标准中定义了这四种隔离级别，即为读未提交，读已提交，可重复读，串行化。&lt;/p&gt;
&lt;p&gt;需要特别注意，这四种隔离级别只是SQL92标准中定义的四个概念。当时数据库的隔离级别实现方式主要是通过锁。并且这个意义上的锁应该是行级锁，这样才有了幻读，可重复读，脏读这些概念。而如今数据库多采用snapshot的方式来实现MVCC（多版本并发），通过获取snapshot的方式来区别这四种隔离级别。&lt;/p&gt;
&lt;p&gt;个人认为在使用snapshot方式时，在一个事务中,如果获取多次snapshot则可实现对应的读已提交；如果只在事务开始时只获取一次snapshot则可实现可重复读和串行化，这类情况实现的可重复读和串行化好像没有区别，都能满足定义的基本要求。这个仅仅是个人理解，如果有不同意见大家可以留言一起讨论下。&lt;/p&gt;
&lt;p&gt;下面再介绍几个事务中相关的概念：&lt;/p&gt;
&lt;p&gt;1 读未提交（Read Uncommitted）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中可以看到其他事务没有提交的新插入的记录，而且能看到其他事务没有提交的对已有记录的更新。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;2 读已提交（Read Commited）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中可以看到其他事务已经提交的新插入的记录，而且能看到其他事务已经提交的对已有记录的更新。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;3 可重复读（Repeatable Read）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中可以看到其他事务已经提交的新插入的记录，但是不能看到其他其他事务对已有记录的更新。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;4 串行化（Serializable）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中完全看不到其他事务对数据库所做的更新（事务执行的时候不允许别的事务并发执行，事务串行化执行，事务只能一个接着一个地执行，而不能并发执行）。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;5 脏读&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务读到另一个事务未提交的更新数据（A和B事务并发执行，B事务执行更新后，A事务查询B事务没有提交的数据，B事务回滚，则A事务得到的数据不是数据库中的真实数据。也就是脏数据，即和数据库中不一致的数据）。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;6 不可重复读&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中完全看不到其他事务对数据库所做的更新（事务执行的时候不允许别的事务并发执行，事务串行化执行，事务只能一个接着一个地执行，而不能并发执行）。&lt;/h6&gt;
&lt;h6&gt;不可重复读中有个特例，叫覆盖更新，是指一个事务覆盖另一个事务已提交的更新数据（即A事务更新数据，然后B事务更新该数据，A事务查询发现自己更新的数据变了）。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;7 虚读（幻读）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务读到另一个事务已提交的新插入的数据（A和B事务并发执行，A事务查询数据，B事务插入或者删除数据，A事务再次查询发现结果集中有以前没有的数据或者以前有的数据消失了）。&lt;/h6&gt;
&lt;/blockquote&gt;</summary></entry><entry><title>数据库中的事务处理</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-shi-wu-chu-li.html" rel="alternate"></link><updated>2015-07-12T00:00:00+02:00</updated><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-07-12:shu-ju-ku-zhong-de-shi-wu-chu-li.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;事务处理是传统关系型数据库中至关重要的特性之一，通俗的讲就是当数据库在一个事务内的一组SQL要么全部执行成功要么全部执行失败，不能出现一个事务内有的SQL执行成功，有的执行SQL执行失败。这样才可以保证事务的一致性，典型的例子就是通常大家所有的银行转账系统。&lt;/p&gt;
&lt;p&gt;与事务相关的通常有以下几个概念: ACID , CAP , 事物隔离级别下面将先介绍ACID与CAP定义，后面将介绍事务的隔离级别。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ACID&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;A：原子性（Atomicity）&lt;/p&gt;
&lt;h6&gt;整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。&lt;/h6&gt;
&lt;p&gt;C：一致性（Consistency）&lt;/p&gt;
&lt;h6&gt;在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。&lt;/h6&gt;
&lt;p&gt;I：隔离性（Isolation）&lt;/p&gt;
&lt;h6&gt;隔离状态执行事务，使它们好像是系统在给定时间内执行的唯一操作。如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或序列化请求，使得在同一时间仅有一个请求用于同一数据。&lt;/h6&gt;
&lt;p&gt;D：持久性（Durability）&lt;/p&gt;
&lt;h6&gt;在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;CAP&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;C:一致性（Consistnecy）&lt;/p&gt;
&lt;h6&gt;所有的节点上的数据时刻保持同步&lt;/h6&gt;
&lt;p&gt;A：可用性（Avaliability ）&lt;/p&gt;
&lt;h6&gt;每个请求都能接受到一个响应，无论响应成功或失败&lt;/h6&gt;
&lt;p&gt;P：分区容忍性（Partition-tolerance）&lt;/p&gt;
&lt;h6&gt;系统应该能持续提供服务，即使系统内部有消息丢失（分区）&lt;/h6&gt;
&lt;h5&gt;CAP理论在分布式系统中通常被证明为只能满足其二不可三者兼得。&lt;/h5&gt;
&lt;/blockquote&gt;</summary></entry><entry><title>github的历程</title><link href="http://rogerarm.github.io/githubde-li-cheng.html" rel="alternate"></link><updated>2015-07-05T00:00:00+02:00</updated><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-07-05:githubde-li-cheng.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;记得刚开github帐号的时候是研二的时候，觉得好奇就注册了个帐号，但是后来对这个帐号也没有发布具体的开源项目。&lt;/p&gt;
&lt;p&gt;在学校的时候一直忙于实验室的项目，也没有时间写点自己喜欢的东西。后来暑假的时候有空就把自己平时使用C++写的一个网页抓取程序传入到github了，虽然很简单，但是总算填补了github上没有具体贡献的空洞了。&lt;/p&gt;
&lt;p&gt;后来到了研三终于有点空了，当时也是看到搭建的github上的博客，觉得好奇就自己使用Pelican模板建立了一个，刚建立后还是很开心的，终于有了自己的博客了。&lt;/p&gt;
&lt;p&gt;本以为以后可以好好维护下的，谁知后来忙于找工作，毕业论文，学车，毕业，学生时代就这么匆匆的过去了。&lt;/p&gt;
&lt;p&gt;自14年3月份参加工作后，觉得自己慢慢的变懒了，相比学生时代的好学精神的确差了很多。&lt;/p&gt;
&lt;p&gt;工作这段时间对分布式数据库的思考比较多，如分布式事务，checkpoint，undo/redo，备份恢复，高可用，负载均衡等。传统数据库的基本理论还是挺高深的，所以一直想抽点时间出来总结一下，但是一直没有空，这次决定不管多忙都写的心得吧，希望一个星期可以总结一次。&lt;/p&gt;</summary></entry><entry><title>刚刚建立的博客</title><link href="http://rogerarm.github.io/gang-gang-jian-li-de-bo-ke.html" rel="alternate"></link><updated>2013-09-01T00:00:00+02:00</updated><author><name>Roger</name></author><id>tag:rogerarm.github.io,2013-09-01:gang-gang-jian-li-de-bo-ke.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;以前一直想建立个自己的博客网站，但一直太忙，刚好最近两天有空，就折腾了一番。&lt;/p&gt;
&lt;p&gt;使用了github的二级域名和Pelican的博客框架，感觉还是挺好玩的，唯一遗憾的就是在本地安装markdown编辑软件的时候迟迟没有成功，郁闷了好久，后来索性就直接用在线编辑器stackedit了，也免去了以后升级的麻烦，现在看看还挺好。&lt;/p&gt;
&lt;p&gt;第一篇博客，也不写那么多了，希望以后能有空一直写下去，作为一种爱好吧。&lt;/p&gt;</summary></entry></feed>