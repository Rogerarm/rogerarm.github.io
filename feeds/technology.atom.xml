<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Roger</title><link href="http://rogerarm.github.io/" rel="alternate"></link><link href="http://rogerarm.github.io/feeds/technology.atom.xml" rel="self"></link><id>http://rogerarm.github.io/</id><updated>2015-08-24T00:00:00+02:00</updated><entry><title>数据库中的High availability</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-high-availability.html" rel="alternate"></link><published>2015-08-24T00:00:00+02:00</published><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-08-24:shu-ju-ku-zhong-de-high-availability.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在传统关系型数据库中有一个非常重要的特性就是high availability，简称高可用。简而言之就是如果一台服务器坏了，仍然系统要保证可用性，通常的实现方式有以下几种，&lt;/p&gt;
&lt;blockquote&gt;
&lt;h5&gt;1： 使用一主一备或多备的方式来同步数据；&lt;/h5&gt;
&lt;h5&gt;2： 使用共享磁阵的方式共享数据；&lt;/h5&gt;
&lt;h5&gt;3： 使用分布式文件系统来保证数据的安全；&lt;/h5&gt;
&lt;/blockquote&gt;
&lt;p&gt;本篇博客只探讨单机数据库中的高可用，对于分布式数据库中的高可用可以到下次再探讨。&lt;/p&gt;
&lt;p&gt;通常单机数据库采用方法1来实现high availability，一台服务器作为主机，另一台作为热备。主机实时将事务日志xlog同步给备机，备机将日志写盘后回复主机写入的位置（例如LSN，一个uint64位顺序递增数值，并假设它永远用不完），主机将事务等待队列中小于该LSN的事务全部提交。&lt;/p&gt;
&lt;p&gt;主备复制流程如图1所示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Note left of Primary: start transaction
Note left of Primary: flush xlog to disk
Primary-&amp;gt;Standby: send xlog to Standby
Note right of Standby: flush xlog to disk
Standby-&amp;gt;Primary: reply xlog location to Primary
Note left of Primary: commit transaction
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用主备方案时，通常会有一套第三方的集群管理软件来监测主备机的状态，当主机宕机时，第三方集群管理软件可以将备机升主，使业务做到不间断。
这样看是完美，然而如果第三方集群管理软件一旦与主机网络断连，误以为主机宕机，让备机升主，此时出现双主，然而由图1可知，主机开始一个事务是先刷写xlog，再发送给备机，当出现双主时，两个主机均会写下日志，此时这一对主备的xlog便出现不一致，即使重启一个主机将其设为备机也无法与新主机同步，因为已经有不一样的xlog日志了。
在PostgreSQL与MySQL数据库中经常会遇到这类问题。当主备设置为同步模式时，可以避免数据一致性的问题，因为没有备机写事务无法提交。&lt;/p&gt;
&lt;p&gt;解决这个问题的方法有两个：&lt;/p&gt;
&lt;blockquote&gt;
&lt;h5&gt;1： 修改主机写xlog的顺序，当主机将一个事务产生的xlog发送到备机后，自己再flush磁盘，这样便可以避免双主后的主备xlog不一致。&lt;/h5&gt;
&lt;h5&gt;2： 将备机进行重建，重建分为两种，一种是全量重建，如果主机数据量很大时，全量重建将非常耗时，这并不符合高可用的理念；另一种是增量重建，就是将双主中不一样的xlog开始分析，以一个主机为准，将另一个主机中不一样的xlog进行undo。以PostgreSQL为例，它并没有日志undo机制，因此这个问题在PostgreSQL中一直是个难题。然而最近发布的PG9.5版本中增加了一个工具pg_rewind，可以使用增量build的方式来解决双主的问题。&lt;/h5&gt;
&lt;/blockquote&gt;</summary></entry><entry><title>数据库中的full page write</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-full-page-write.html" rel="alternate"></link><published>2015-08-09T00:00:00+02:00</published><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-08-09:shu-ju-ku-zhong-de-full-page-write.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在传统关系型数据库中有一个功能称为full page write，这个功能是为了避免机械磁盘在写的时候无法保证原子性而设计的，也可以认为是一个古老的功能，但是其思想值得借鉴。以下以PostgreSQL数据库的实现为例子解释这一设计思想。&lt;/p&gt;
&lt;p&gt;假设每次写事务日志时都有一个唯一的标记称为LSN，它顺序增长，假设用不完。我们在写每条日志时头部都有LSN标记。&lt;/p&gt;
&lt;p&gt;当数据库系统运行时，如果此时系统正在刷写页面（假设page大小为8KB）时系统断电，当该服务器使用的磁盘不带电池时，磁盘刷写数据只能保证512B字节的原子性（因为磁盘的一个扇区是512B） 。 因此此时可能造成一个页面中只有页头的512B刷写到磁盘上，而剩下的数据未更新，此时如果系统启动重新恢复过程中，首先会判断该LSN是否比恢复日志中的LSN大，如果大表示页面数据为未来的，即跳过恢复。然而此时页面数据因为不具有原子性并不是最新，导致数据出现不一致。&lt;/p&gt;
&lt;p&gt;解决这个问题的一个方法就是在每次checkpoint之后，如果读取的一个页面是第一次读取，更改该页面时，也就是写更新该页面xlog日志时把整个页面写入xlog中，如果在后面宕机再恢复时无条件将该页面替换磁盘上的页面，因为此时磁盘上的页面可能无法保证页面的原子性。而后面的日志恢复过程中，可能刷坏的页面已经被替换掉，LSN的判断也不可能出现错误，因此可以有效的解决该问题。&lt;/p&gt;
&lt;p&gt;该方法的一个缺陷就是可能会造成xlog日志文件很大，在主备同步过程中，网络传输的日志过多，造成性能下降。&lt;/p&gt;
&lt;p&gt;然而在现代数据库系统中使用的磁盘通常可能带电池，而可以保证写page的原子性，因此该功能通常可以关闭。并且未来可能会使用更高端的存储介质，比如SSD或NVRAM，性能将是机械磁盘的几个数量级。但是该问题的解决方案还是值得借鉴的，在我们无法保证磁盘上页面数据最新并且完整时，可以使用该full page write思想，出现这个情况的场景比如时，并行恢复，数据页复制等等情况下。&lt;/p&gt;</summary></entry><entry><title>数据库中的checkpoint</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-checkpoint.html" rel="alternate"></link><published>2015-08-02T00:00:00+02:00</published><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-08-02:shu-ju-ku-zhong-de-checkpoint.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在上一篇博客中我们讲到目前大众型的关系型数据库都采用了WAL思想，就是将page的更新只在内存中操作，并记录相应的事务日志，提交事务时保证事务日志先提交。&lt;/p&gt;
&lt;p&gt;然而我们可以考虑这里面的一个问题，就是装载page的内存容量到底要设多大才合适，工程中服务器的内存是有限的，假设设置为4GB大小，那么这4GB用完了怎么办呢？还有就是我们记录的事务日志（假设称其为xlog）多久才删除呢？&lt;/p&gt;
&lt;p&gt;这便涉及到另一个通常使用的思想叫checkpoint，目前大部分的关系型数据库都会使用这一技术。简而言之就是当到一定时候我们就把内存中的数据全部刷盘，然后删除这个时间点之前的所有xlog，因为这个时间点所有的内存数据都刷到磁盘了，之前的这些xlog已经不需要恢复了，下次系统如果出现异常，数据库系统便可以从最近一次checkpoint点来启动恢复，重新redo回内存中的这些操作。&lt;/p&gt;
&lt;p&gt;使用这个方法便便可以保证数据库系统可以循环并正常的运行了，通常checkpoint启动可以受xlog个数，时间，业务线程的请求等等控制。并且系统在做checkpoint时会将大量的page fsync到磁盘，因此此时的IO量很大，通常此时性能不好，使用TPCC测试时可以看到tpmc的曲线在这个点出现明显的下降。&lt;/p&gt;
&lt;p&gt;解决这个问题的一个方法就是系统中可以再运行一个后台线程，慢慢的整理内存中的page数据，将没有弄脏的page扔掉，慢慢的刷写一些page，可以腾出一些内存空间，以防数据库的内存空间因为满了而导致系统性能下降，也可以降低checkpoint启动时造成的系统性能下降的时间窗。&lt;/p&gt;</summary></entry><entry><title>数据库中的WAL</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-wal.html" rel="alternate"></link><published>2015-07-26T00:00:00+02:00</published><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-07-26:shu-ju-ku-zhong-de-wal.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在数据库系统中，通常大家会讨论到WAL，其称为write-ahead log，预写式日志。是目前传统关系型数据库中提升事务提交性能的一种常用方法。&lt;/p&gt;
&lt;p&gt;在描述WAL之前，我们先讨论下数据库存储的实现方式。&lt;/p&gt;
&lt;p&gt;在计算机系统刚刚萌芽期间，人们希望可以将一些结构化数据（比如一张表数据）存储起来，并且具有永久性。通常的做法就是将这些数据一行一行的写入一个文件，当想使用时便打开一行一行读取，当然写入和打开都是通过程序让计算机去操作。当数据操作不是很频繁时，这样不失为一种好方法。&lt;/p&gt;
&lt;p&gt;然而如果数据在频繁的做操作，每次读取磁盘和写入磁盘都是非常耗时的。那么人们便想，CPU操作内存的速度是操作磁盘速度的几十甚至几百倍，能不能将数据按页面划分，将这些页面读取到内存中，每次数据库系统在更新时都直接更新内存中的数据页面，而不用每次去读写磁盘。&lt;/p&gt;
&lt;p&gt;然而当系统一直运行正常的时候，性能固然是很好，但是一旦系统出现异常宕机时，内存中的数据便永久丢失，这在数据库系统中是绝对不允许的。解决这个问题的方法就是每次在提交事务之前记录事务日志，并且将事务日志刷到磁盘上后再提交事务。这样便保证了即使系统宕机，再次启动的时候数据库也可以从事务日志中恢复内存中的数据，这便是WAL，这些日志通常也被称为redo日志。&lt;/p&gt;
&lt;p&gt;可能大家会有个疑问，同样都是要fsync到磁盘，写wal与写page有什么区别呢？这便涉及机械磁盘中一个随机IO与顺序IO的问题。写wal时是所有事务日志都写到一个文件中，最后fsync到磁盘就可以。而写page时会涉及到不同表和不同page的文件，因此需要随机的写磁盘上不同位置，这样在机械磁盘的实现上是相对较慢的。&lt;/p&gt;
&lt;p&gt;使用写事务日志来代替频繁的读写磁盘，可以提升数据库的并发性能，因此wal也是关系型数据库乃至其它新型分布式系统中一种常用的技术。&lt;/p&gt;</summary></entry><entry><title>事务隔离级别</title><link href="http://rogerarm.github.io/shi-wu-ge-chi-ji-bie.html" rel="alternate"></link><published>2015-07-19T00:00:00+02:00</published><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-07-19:shi-wu-ge-chi-ji-bie.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;在数据库系统中，如果每个并发操作都是原子的，就好比如果都是
&lt;code&gt;set a = 3;&lt;/code&gt;
这类的简单操作，那么数据库系统中不需要锁或隔离级别来控制并发，因为它本身就是原子的。&lt;/p&gt;
&lt;p&gt;但是数据库中有一个重要的个功能叫事务，就是可以将多个操作定义为一个事务块，这个事务块要么都成功，要么都失败。这样就加大了数据库在并发时的复杂性。&lt;/p&gt;
&lt;p&gt;解决这个问题的一种方法就是每个单元都加互斥锁，让每个事务串行的进行下去，这就是串行化隔离级别。&lt;/p&gt;
&lt;p&gt;这种方法明显性能不好，无法保证数据库系统的大并发功能。我们可以思考如果把互斥锁改为读写锁，这样在读上可以并发，这是一个性能的提升。使用读写锁时，有两种情况：第一种是读读并发，读读并发可能会造成幻读的情况，这就是可重复读隔离级别。第二种是不仅可以读读并发，还可以读写并发，就是读锁可被升级为写锁，读写并发时不满足可重复读，这就是读已提交隔离级别。&lt;/p&gt;
&lt;p&gt;然后还有一种方法就是只在写时加锁，这样可以实现读读并发，读写并发，写读并发，写读并发过程中会造成脏读，这类隔离级别通常称为读未提交。&lt;/p&gt;
&lt;p&gt;在SQL92标准中定义了这四种隔离级别，即为读未提交，读已提交，可重复读，串行化。&lt;/p&gt;
&lt;p&gt;需要特别注意，这四种隔离级别只是SQL92标准中定义的四个概念。当时数据库的隔离级别实现方式主要是通过锁。并且这个意义上的锁应该是行级锁，这样才有了幻读，可重复读，脏读这些概念。而如今数据库多采用snapshot的方式来实现MVCC（多版本并发），通过获取snapshot的方式来区别这四种隔离级别。&lt;/p&gt;
&lt;p&gt;个人认为在使用snapshot方式时，在一个事务中,如果获取多次snapshot则可实现对应的读已提交；如果只在事务开始时只获取一次snapshot则可实现可重复读和串行化，这类情况实现的可重复读和串行化好像没有区别，都能满足定义的基本要求。这个仅仅是个人理解，如果有不同意见大家可以留言一起讨论下。&lt;/p&gt;
&lt;p&gt;下面再介绍几个事务中相关的概念：&lt;/p&gt;
&lt;p&gt;1 读未提交（Read Uncommitted）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中可以看到其他事务没有提交的新插入的记录，而且能看到其他事务没有提交的对已有记录的更新。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;2 读已提交（Read Commited）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中可以看到其他事务已经提交的新插入的记录，而且能看到其他事务已经提交的对已有记录的更新。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;3 可重复读（Repeatable Read）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中可以看到其他事务已经提交的新插入的记录，但是不能看到其他其他事务对已有记录的更新。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;4 串行化（Serializable）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中完全看不到其他事务对数据库所做的更新（事务执行的时候不允许别的事务并发执行，事务串行化执行，事务只能一个接着一个地执行，而不能并发执行）。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;5 脏读&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务读到另一个事务未提交的更新数据（A和B事务并发执行，B事务执行更新后，A事务查询B事务没有提交的数据，B事务回滚，则A事务得到的数据不是数据库中的真实数据。也就是脏数据，即和数据库中不一致的数据）。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;6 不可重复读&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务在执行过程中完全看不到其他事务对数据库所做的更新（事务执行的时候不允许别的事务并发执行，事务串行化执行，事务只能一个接着一个地执行，而不能并发执行）。&lt;/h6&gt;
&lt;h6&gt;不可重复读中有个特例，叫覆盖更新，是指一个事务覆盖另一个事务已提交的更新数据（即A事务更新数据，然后B事务更新该数据，A事务查询发现自己更新的数据变了）。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;7 虚读（幻读）&lt;/p&gt;
&lt;blockquote&gt;
&lt;h6&gt;一个事务读到另一个事务已提交的新插入的数据（A和B事务并发执行，A事务查询数据，B事务插入或者删除数据，A事务再次查询发现结果集中有以前没有的数据或者以前有的数据消失了）。&lt;/h6&gt;
&lt;/blockquote&gt;</summary></entry><entry><title>数据库中的事务处理</title><link href="http://rogerarm.github.io/shu-ju-ku-zhong-de-shi-wu-chu-li.html" rel="alternate"></link><published>2015-07-12T00:00:00+02:00</published><author><name>Roger</name></author><id>tag:rogerarm.github.io,2015-07-12:shu-ju-ku-zhong-de-shi-wu-chu-li.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;事务处理是传统关系型数据库中至关重要的特性之一，通俗的讲就是当数据库在一个事务内的一组SQL要么全部执行成功要么全部执行失败，不能出现一个事务内有的SQL执行成功，有的执行SQL执行失败。这样才可以保证事务的一致性，典型的例子就是通常大家所有的银行转账系统。&lt;/p&gt;
&lt;p&gt;与事务相关的通常有以下几个概念: ACID , CAP , 事物隔离级别下面将先介绍ACID与CAP定义，后面将介绍事务的隔离级别。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ACID&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;A：原子性（Atomicity）&lt;/p&gt;
&lt;h6&gt;整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。&lt;/h6&gt;
&lt;p&gt;C：一致性（Consistency）&lt;/p&gt;
&lt;h6&gt;在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。&lt;/h6&gt;
&lt;p&gt;I：隔离性（Isolation）&lt;/p&gt;
&lt;h6&gt;隔离状态执行事务，使它们好像是系统在给定时间内执行的唯一操作。如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或序列化请求，使得在同一时间仅有一个请求用于同一数据。&lt;/h6&gt;
&lt;p&gt;D：持久性（Durability）&lt;/p&gt;
&lt;h6&gt;在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;CAP&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;C:一致性（Consistnecy）&lt;/p&gt;
&lt;h6&gt;所有的节点上的数据时刻保持同步&lt;/h6&gt;
&lt;p&gt;A：可用性（Avaliability ）&lt;/p&gt;
&lt;h6&gt;每个请求都能接受到一个响应，无论响应成功或失败&lt;/h6&gt;
&lt;p&gt;P：分区容忍性（Partition-tolerance）&lt;/p&gt;
&lt;h6&gt;系统应该能持续提供服务，即使系统内部有消息丢失（分区）&lt;/h6&gt;
&lt;h5&gt;CAP理论在分布式系统中通常被证明为只能满足其二不可三者兼得。&lt;/h5&gt;
&lt;/blockquote&gt;</summary></entry></feed>